{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Analytics on online content.\n",
    "\n",
    "\n",
    "# Objective\n",
    "\n",
    "The objective of this assignment is to extract textual data articles from the given URL and perform text analysis to compute variables that are explained below. \n",
    "\n",
    "# Data Extraction\n",
    "\n",
    "Input.xlsx\n",
    "\n",
    "For each of the articles, given in the input.xlsx file, extract the article text and save the extracted article in a text file with URL_ID as its file name.\n",
    "\n",
    "While extracting text, please make sure your program extracts only the article title and the article text. It should not extract the website header, footer, or anything other than the article text. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>https://insights.blackcoffer.com/how-are-genet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-ai-use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>https://insights.blackcoffer.com/benefits-of-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>https://insights.blackcoffer.com/how-big-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-ai-m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0       1  https://insights.blackcoffer.com/how-is-login-...\n",
       "1       2  https://insights.blackcoffer.com/how-does-ai-h...\n",
       "2       3  https://insights.blackcoffer.com/ai-and-its-im...\n",
       "3       4  https://insights.blackcoffer.com/how-do-deep-l...\n",
       "4       5  https://insights.blackcoffer.com/how-artificia...\n",
       "5       6  https://insights.blackcoffer.com/how-are-genet...\n",
       "6       7  https://insights.blackcoffer.com/how-is-ai-use...\n",
       "7       8  https://insights.blackcoffer.com/benefits-of-b...\n",
       "8       9  https://insights.blackcoffer.com/how-big-data-...\n",
       "9      10  https://insights.blackcoffer.com/how-will-ai-m..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would derive the text content from each URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://insights.blackcoffer.com/ai-and-its-impact-on-the-fashion-industry/'\n",
    "article = Article(url, language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.download() \n",
    "article.parse() \n",
    "article.nlp() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Title:\n",
      "AI and its impact on the Fashion Industry\n",
      "\n",
      "\n",
      "Article Text:\n",
      "If you were a fan of the 90’s film Clueless back in the day, then you’ll remember the protagonist, Cher Horowitz’s amazing virtual wardrobe. She used it to browse her clothing and choose a perfectly coordinated ensemble. This virtual application, which was just the brainchild of a writer wanting to make the protagonist look rich, fashionable, and ahead of her time, ignited a buzz and prospected having an automated style device to make everyday dress-up fun and engagingly time-saving.\n",
      "\n",
      "Times have changed and technological advancement today is transforming everything from probabilities to possibilities. We are in the era where, machines not just facilitate our tasks and demands but rather suggest, forecasts, and analyze thus making lives simpler and smarter.\n",
      "\n",
      "With the advent of technology, style suggestions are just a fraction of the big picture that AI has painted in the fashion industry today.\n",
      "\n",
      "What is AI?\n",
      "\n",
      "Artificial intelligence is the creation of computer programs capable of performing activities and solving issues that would normally need human intelligence. AI has surged across a variety of industries, with the potential to transform businesses through creative technologies and more effective operational processes.\n",
      "\n",
      "At first, AI automation did not appear to be an appealing tool for fashion leaders to use in an industry focused on creative ability and expression. However, as we enter the hyper-digital era, these apps have the potential to revolutionize enterprises and generate considerable industry growth when compared to competitors that use traditional approaches.\n",
      "\n",
      "Some of the most well-known brands in the business are now investing in algorithms that assist buyers to choose designs. A slew of AI-based start-ups is also assisting everyone from retailers to customers in removing the guesswork from the equation.\n",
      "\n",
      "Impact on fashion\n",
      "\n",
      "This article examines how artificial intelligence has impacted key areas of the fashion industry, as well as explores brands that have benefited from its use.\n",
      "\n",
      "AI in Apparel designing\n",
      "\n",
      "Fashion firms are utilizing technology to better understand client wants and produce better garments thanks to more sophisticated data collection.\n",
      "\n",
      "Tommy Hilfiger pioneered the “Reimagine Retail” project, which trains fashion designers with AI design skills in collaboration with IBM. As a result, fashion students could master a variety of technical skills such as natural language processing (NLP) or computer vision. Fashion students could learn from thousands of fashion-related photos using AI, which increased their inventiveness and shortened lead times for the fashion firm.\n",
      "\n",
      "AI in the Manufacturing process\n",
      "\n",
      "Fashion brands are now able to identify fast-changing fashion trends and get the latest fashion accessories to store shelves faster than the “traditional” fashion shop, thanks to AI and machine learning capabilities. As a result, prominent fashion brands such as Zara, Top Shop, and H&M can provide immediate gratification to retail customers by identifying seasonal trends and producing the appropriate quantity of the current items.\n",
      "\n",
      "AI in Logistics\n",
      "\n",
      "AI in inventory and supply chain management helps to speed up processes by optimizing routes and lowering logistics and shipping costs. Companies use AI to automate logistics and supply chain procedures for speedier delivery or to locate alternate routes for vehicles that have been detoured due to unanticipated situations like bad weather or road construction.\n",
      "\n",
      "Owing to lockdown, major fashion firms had to rethink their go-to-market strategy overnight, with actual brick-and-mortar stores closed and people staying away from shopping malls. Myntra finds itself in a unique position to assist them.\n",
      "\n",
      "Myntra moved its whole data infrastructure, including supply chain management, inventory, and website capabilities, to Microsoft Azure just before the pandemic. Apart from giving Myntra the flexibility to respond to demand spikes, Azure’s built-in Machine Learning technologies sped up the development of advanced analytics capabilities, allowing them to better understand their customers.\n",
      "\n",
      "AI in Fashion Retail\n",
      "\n",
      "In retail, AI and machine learning are also providing an automated solution to monitor customer activities while shopping and visualize their sentiments to learn what products they prefer to buy and what products they ignore.\n",
      "\n",
      "AI can also track traffic in retail stores or record consumer shopping experiences, with the option of receiving feedback on how their experience was while shopping at the store, allowing them to enhance their services.\n",
      "\n",
      "Uniqlo has AI-powered UMood kiosks that offer clients a selection of products and use neurotransmitters to assess their reaction to color and style. The kiosk then makes product recommendations based on each person’s reactions. Customers don’t even need to press a button for the system to know how they feel about each item; their brain signals are plenty.\n",
      "\n",
      "AI Fashion Stylist — Styling the Fashion Accessories\n",
      "\n",
      "Furthermore, AI in fashion is enabling each of us to find those elusive perfect garments that suit our body types and fashion preferences.\n",
      "\n",
      "These AI-enabled garments and ensembles are personalized to the user’s style, body type, colors, and current fashion trends, as well as different situations and weather.\n",
      "\n",
      "iLUK is an AI-based personal stylist that uses Computer Vision and 3D Reconstruction technology at its core to provide technology-based personal styling. It’s shaped like a pod that will be placed in a store.\n",
      "\n",
      "AI in Fast Fashion with Smart Mirror\n",
      "\n",
      "Similarly, a smart mirror driven by AI is being utilized by a company to streamline consumers’ shopping experiences by allowing them to virtually visualize how items would appear on them without having to put them on their bodies.\n",
      "\n",
      "The AI smart mirror with touch screen glasses is mounted in the changing room of retail stores and relays information on whether or not a person is inside. Customers can also use this mirror to try on other sizes and colors, as well as receive tailored mix-and-match alternatives to complete the appearance.\n",
      "\n",
      "Van Heusen designed a storage space that includes a “Virtual Trial” mirror that allows customers to view how clothes might appear on them by scanning the item’s barcode and stepping in front of the mirror while virtual clothing is projected onto their reflection.\n",
      "\n",
      "AI in Ecommerce\n",
      "\n",
      "In the same way that AI is revolutionizing retail fashion stores, AI is revolutionizing online purchasing and E-commerce. While browsing or searching for fashion goods on e-commerce sites, AI suggests additional items that are similar to what you’re looking for based on your color preferences, budget, and other factors. It analyses your search history data and suggests more relevant stuff you should look at.\n",
      "\n",
      "Amazon has undoubtedly transformed the online shopping experience with its AI-powered product suggestion engine. Amazon is implementing an AI-enabled fashion designer algorithm that can create clothing by mimicking the design styles of several popular garments and applying them to a new garment. The Echo Look fashion assistant, which uses machine learning to deliver personalized recommendations, is Amazon’s other use case.\n",
      "\n",
      "AI in Visual Search — To Find the Products Using Camera\n",
      "\n",
      "AI-based visual search technology is now employed by E-commerce stores to comprehend the content and context of these photographs and produce a list of related results. You can capture an object using your camera and then search for it online. Retailers can use AI-enabled computer vision-based visual search technology to propose thematically or aesthetically relevant items to customers in a way that would be difficult to do with only a word query.\n",
      "\n",
      "Neiman Marcus, a high-end department store, employs artificial intelligence to make it easier for shoppers to locate things. The Snap. Find. Shop. the app allows users to photograph items they encounter while out and about, and then search Neiman Marcus’ inventory for the same or a comparable item.\n",
      "\n",
      "AI in Fashion and Sustainability\n",
      "\n",
      "One of the most damaging businesses on the earth is the fashion industry. Artificial Intelligence can be used in conjunction with Machine Learning, Deep Learning, Natural Language Processing, Visual Recognition, and Data Analytics to reduce trend prediction errors and more precisely forecast patterns, leading to fewer garments being manufactured and subsequently underutilized.\n",
      "\n",
      "The H&M Group is using “Amplified Intelligence,” which combines analytics and AI with human intelligence.\n",
      "\n",
      "Using artificially intelligent technologies, H&M is enhancing its ability to recognize trends and organize logistics, as well as minimizing the frequency of discounted deals and large amounts of unsold goods.\n",
      "\n",
      "Though intelligence per se is artificial, nevertheless is likely to have an earnest impact, both positive and negative:\n",
      "\n",
      "The fashion dilemma\n",
      "\n",
      "Apparel manufacture is a labor-intensive industry in the fashion industry. AI-enabled machines and robots can perfectly stitch fabrics while also detecting fabric flaws and providing quality assurance to ensure that the actual design hues will match the new colors.\n",
      "\n",
      "In nations like Bangladesh, where the garment industry accounts for 80% of the GDP, this will have a significant influence on the labor force in the long run. It is already feeling the heat from these specialized AI-based devices, thus jeopardizing the jobs of breadwinners.\n",
      "\n",
      "AI should not be viewed as a rival, but rather as a collaborator. The cost and ethics of AI are currently preventing us from progressing. We must be careful not to use technology to increase inequity or exacerbate social injustice. We also need to find a balance and integrate humanity into the machines we’re constructing in the future.\n",
      "\n",
      "Virtual wonderland\n",
      "\n",
      "“We are being monitored and classified by AI in portions of our lives that were not previously watched,” says Sophie Hackford, a futurist and keynote speaker. She wonders if we’ve built the “wrong” internet. We created it intending to monetize our viewers in mind, rather than the dynamic knowledge-sharing area that Tim Berners-Lee envisioned at the start.” She believes that in the future, we will be much more selective in how we obtain information, and that “bots” would be critical in meeting our requirements. As a result, the gains will come at the expense of our privacy.\n",
      "\n",
      "As numerous as AI’s advantages are, it is impossible to ignore the difficult issues it brings. With everything being data-driven, there is a pressing need to establish boundaries to build a shared ecosystem that benefits both businesses and the general public.\n",
      "\n",
      "Conclusion\n",
      "\n",
      "Finding a wise balance between physical stores and online stores will continue to be a crucial issue in an industry where brick-and-mortar retail locations are still an important element of the sector’s approach to business.\n",
      "\n",
      "The usefulness of chatbots aimed at improving online and in-store product navigation shows significant promise for preserving customer attention and use in the near term. We expect consumers to become accustomed to these capabilities over time, and the field to become more competitive as AI becomes more broadly applied, as prominent brands set the tone with their usage of AI.\n",
      "\n",
      "It’s too early to tell how these AI applications will affect earnings and cost savings because prominent fashion firms are still in the early stages of AI implementation. However, there will be a learning curve as corporations figure out how consumers react to these innovation efforts, which could have a direct influence on sales.\n",
      "\n",
      "Blackcoffer Insights 33: Lakshman Upadhyay and Prabhlin Kaur Matta, Welingkar Institute of M D R, Mumbai\n",
      "\n",
      "\n",
      "Article Summary:\n",
      "Impact on fashionThis article examines how artificial intelligence has impacted key areas of the fashion industry, as well as explores brands that have benefited from its use.\n",
      "AI Fashion Stylist — Styling the Fashion AccessoriesFurthermore, AI in fashion is enabling each of us to find those elusive perfect garments that suit our body types and fashion preferences.\n",
      "AI in EcommerceIn the same way that AI is revolutionizing retail fashion stores, AI is revolutionizing online purchasing and E-commerce.\n",
      "AI in Fashion and SustainabilityOne of the most damaging businesses on the earth is the fashion industry.\n",
      "Though intelligence per se is artificial, nevertheless is likely to have an earnest impact, both positive and negative:The fashion dilemmaApparel manufacture is a labor-intensive industry in the fashion industry.\n",
      "\n",
      "\n",
      "Article Keywords:\n",
      "['stores', 'industry', 'intelligence', 'search', 'technology', 'impact', 'shopping', 'ai', 'learning', 'retail', 'fashion']\n"
     ]
    }
   ],
   "source": [
    "print(\"Article Title:\") \n",
    "print(article.title) #prints the title of the article\n",
    "print(\"\\n\") \n",
    "print(\"Article Text:\") \n",
    "print(article.text) #prints the entire text of the article\n",
    "print(\"\\n\") \n",
    "print(\"Article Summary:\") \n",
    "print(article.summary) #prints the summary of the article\n",
    "print(\"\\n\") \n",
    "print(\"Article Keywords:\")\n",
    "print(article.keywords) #prints the keywords of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(url):\n",
    "    \n",
    "    url1 = url\n",
    "    article = Article(url1, language=\"en\")\n",
    "    \n",
    "    article.download() \n",
    "    article.parse() \n",
    "    article.nlp()\n",
    "    \n",
    "    return article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-3d5836659288>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['URL_ID'][i] = get_text(df['URL'][i])\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(df)):\n",
    "    df['URL_ID'][i] = get_text(df['URL'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'URL_ID':'Text'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When people hear AI they often think about sen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With increasing computing power and more data,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you were a fan of the 90’s film Clueless ba...</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the stone age to the modern world, from h...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Artificial intelligence (AI) is the developmen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-are-genet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Artificial intelligence (AI) is the most impor...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-ai-use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>“In God we trust, all others must bring data.”...</td>\n",
       "      <td>https://insights.blackcoffer.com/benefits-of-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Big data refers to large sets of unstructured,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-big-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Artificial intelligence (AI) is intelligence d...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-ai-m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  When people hear AI they often think about sen...   \n",
       "1  With increasing computing power and more data,...   \n",
       "2  If you were a fan of the 90’s film Clueless ba...   \n",
       "3  Understanding exactly how data is ingested, an...   \n",
       "4  From the stone age to the modern world, from h...   \n",
       "5  Artificial intelligence (AI) is the developmen...   \n",
       "6  Artificial intelligence (AI) is the most impor...   \n",
       "7  “In God we trust, all others must bring data.”...   \n",
       "8  Big data refers to large sets of unstructured,...   \n",
       "9  Artificial intelligence (AI) is intelligence d...   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://insights.blackcoffer.com/how-is-login-...  \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...  \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...  \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...  \n",
       "4  https://insights.blackcoffer.com/how-artificia...  \n",
       "5  https://insights.blackcoffer.com/how-are-genet...  \n",
       "6  https://insights.blackcoffer.com/how-is-ai-use...  \n",
       "7  https://insights.blackcoffer.com/benefits-of-b...  \n",
       "8  https://insights.blackcoffer.com/how-big-data-...  \n",
       "9  https://insights.blackcoffer.com/how-will-ai-m...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some Text preprocessing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(text):\n",
    "\n",
    "    review = re.sub('[^a-zA-Z0-9]', ' ',text)  # except small and capital letters and numeric remove everythong.\n",
    "    review = review.lower()                    # lower it.\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [word for word in review if not word in stopwords.words('english')]   # remove stopwords.\n",
    "    review = ' '.join(review)\n",
    "    return review\n",
    "\n",
    "\n",
    "df['Transform_Text'] = df['Text'].apply(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "For each of the extracted texts from the article, perform textual analysis and compute variables.\n",
    "\n",
    "I am looking for these variables in the analysis document:\n",
    "\n",
    "POSITIVE SCORE\n",
    "\n",
    "NEGATIVE SCORE\n",
    "\n",
    "POLARITY SCORE\n",
    "\n",
    "SUBJECTIVITY SCORE\n",
    "\n",
    "AVG SENTENCE LENGTH\n",
    "\n",
    "PERCENTAGE OF COMPLEX WORDS\n",
    "\n",
    "FOG INDEX\n",
    "\n",
    "AVG NUMBER OF WORDS PER SENTENCE\n",
    "\n",
    "COMPLEX WORD COUNT\n",
    "\n",
    "WORD COUNT\n",
    "\n",
    "SYLLABLE PER WORD\n",
    "\n",
    "PERSONAL PRONOUNS\n",
    "\n",
    "AVG WORD LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count in each text row.\n",
    "\n",
    "df['word_counts'] = df['Transform_Text'].apply(lambda x: len(str(x).split()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.sent_tokenize(df['Text'][0]))  # checking length function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-75181261230b>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average number of words per sentence'][i] = df['word_counts'][i]/len(nltk.sent_tokenize(df['Text'][i]))\n"
     ]
    }
   ],
   "source": [
    "df['average number of words per sentence'] = np.nan\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    \n",
    "    df['average number of words per sentence'][i] = df['word_counts'][i]/len(nltk.sent_tokenize(df['Text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When people hear AI they often think about sen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>people hear ai often think sentient robots mag...</td>\n",
       "      <td>434</td>\n",
       "      <td>18.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With increasing computing power and more data,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>increasing computing power data potential valu...</td>\n",
       "      <td>383</td>\n",
       "      <td>13.678571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you were a fan of the 90’s film Clueless ba...</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>fan 90 film clueless back day remember protago...</td>\n",
       "      <td>1103</td>\n",
       "      <td>14.324675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>understanding exactly data ingested analyzed r...</td>\n",
       "      <td>254</td>\n",
       "      <td>16.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the stone age to the modern world, from h...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>stone age modern world hunting gathering culti...</td>\n",
       "      <td>711</td>\n",
       "      <td>10.611940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Artificial intelligence (AI) is the developmen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-are-genet...</td>\n",
       "      <td>artificial intelligence ai development compute...</td>\n",
       "      <td>701</td>\n",
       "      <td>14.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Artificial intelligence (AI) is the most impor...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-ai-use...</td>\n",
       "      <td>artificial intelligence ai important branch co...</td>\n",
       "      <td>920</td>\n",
       "      <td>14.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>“In God we trust, all others must bring data.”...</td>\n",
       "      <td>https://insights.blackcoffer.com/benefits-of-b...</td>\n",
       "      <td>god trust others must bring data w edwards dem...</td>\n",
       "      <td>1138</td>\n",
       "      <td>14.405063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Big data refers to large sets of unstructured,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-big-data-...</td>\n",
       "      <td>big data refers large sets unstructured semi s...</td>\n",
       "      <td>1008</td>\n",
       "      <td>12.759494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Artificial intelligence (AI) is intelligence d...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-ai-m...</td>\n",
       "      <td>artificial intelligence ai intelligence demons...</td>\n",
       "      <td>338</td>\n",
       "      <td>9.657143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  When people hear AI they often think about sen...   \n",
       "1  With increasing computing power and more data,...   \n",
       "2  If you were a fan of the 90’s film Clueless ba...   \n",
       "3  Understanding exactly how data is ingested, an...   \n",
       "4  From the stone age to the modern world, from h...   \n",
       "5  Artificial intelligence (AI) is the developmen...   \n",
       "6  Artificial intelligence (AI) is the most impor...   \n",
       "7  “In God we trust, all others must bring data.”...   \n",
       "8  Big data refers to large sets of unstructured,...   \n",
       "9  Artificial intelligence (AI) is intelligence d...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4  https://insights.blackcoffer.com/how-artificia...   \n",
       "5  https://insights.blackcoffer.com/how-are-genet...   \n",
       "6  https://insights.blackcoffer.com/how-is-ai-use...   \n",
       "7  https://insights.blackcoffer.com/benefits-of-b...   \n",
       "8  https://insights.blackcoffer.com/how-big-data-...   \n",
       "9  https://insights.blackcoffer.com/how-will-ai-m...   \n",
       "\n",
       "                                      Transform_Text  word_counts  \\\n",
       "0  people hear ai often think sentient robots mag...          434   \n",
       "1  increasing computing power data potential valu...          383   \n",
       "2  fan 90 film clueless back day remember protago...         1103   \n",
       "3  understanding exactly data ingested analyzed r...          254   \n",
       "4  stone age modern world hunting gathering culti...          711   \n",
       "5  artificial intelligence ai development compute...          701   \n",
       "6  artificial intelligence ai important branch co...          920   \n",
       "7  god trust others must bring data w edwards dem...         1138   \n",
       "8  big data refers large sets unstructured semi s...         1008   \n",
       "9  artificial intelligence ai intelligence demons...          338   \n",
       "\n",
       "   average number of words per sentence  \n",
       "0                             18.083333  \n",
       "1                             13.678571  \n",
       "2                             14.324675  \n",
       "3                             16.933333  \n",
       "4                             10.611940  \n",
       "5                             14.604167  \n",
       "6                             14.838710  \n",
       "7                             14.405063  \n",
       "8                             12.759494  \n",
       "9                              9.657143  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Word Length\n",
    "\n",
    "\n",
    "Average Word Length is calculated by the formula:\n",
    "    \n",
    "( Sum of the total number of characters in each word ) / ( Total number of words )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_count(x):\n",
    "    s = x.split()\n",
    "    x = ''.join(s)\n",
    "    return len(x)      # counting the total number of characters in each text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chara_count'] = df['Transform_Text'].apply(lambda x: char_count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to check for stopwords in each text.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "df['stopwords'] = df['Text'].apply(lambda x: [t for t in x.split() if t  in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-2b95d69bd553>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average word length'][i] = df['chara_count'][i]/df['word_counts'][i]\n"
     ]
    }
   ],
   "source": [
    "df['average word length'] = np.nan\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    \n",
    "    df['average word length'][i] = df['chara_count'][i]/df['word_counts'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>chara_count</th>\n",
       "      <th>average word length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When people hear AI they often think about sen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>people hear ai often think sentient robots mag...</td>\n",
       "      <td>434</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>2780</td>\n",
       "      <td>6.405530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With increasing computing power and more data,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>increasing computing power data potential valu...</td>\n",
       "      <td>383</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>2618</td>\n",
       "      <td>6.835509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you were a fan of the 90’s film Clueless ba...</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>fan 90 film clueless back day remember protago...</td>\n",
       "      <td>1103</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>7515</td>\n",
       "      <td>6.813237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>understanding exactly data ingested analyzed r...</td>\n",
       "      <td>254</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>1778</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the stone age to the modern world, from h...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>stone age modern world hunting gathering culti...</td>\n",
       "      <td>711</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>4640</td>\n",
       "      <td>6.526020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  When people hear AI they often think about sen...   \n",
       "1  With increasing computing power and more data,...   \n",
       "2  If you were a fan of the 90’s film Clueless ba...   \n",
       "3  Understanding exactly how data is ingested, an...   \n",
       "4  From the stone age to the modern world, from h...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4  https://insights.blackcoffer.com/how-artificia...   \n",
       "\n",
       "                                      Transform_Text  word_counts  \\\n",
       "0  people hear ai often think sentient robots mag...          434   \n",
       "1  increasing computing power data potential valu...          383   \n",
       "2  fan 90 film clueless back day remember protago...         1103   \n",
       "3  understanding exactly data ingested analyzed r...          254   \n",
       "4  stone age modern world hunting gathering culti...          711   \n",
       "\n",
       "   average number of words per sentence  chara_count  average word length  \n",
       "0                             18.083333         2780             6.405530  \n",
       "1                             13.678571         2618             6.835509  \n",
       "2                             14.324675         7515             6.813237  \n",
       "3                             16.933333         1778             7.000000  \n",
       "4                             10.611940         4640             6.526020  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYLLABLE COUNT\n",
    "\n",
    "We count the number of Syllables in each word of the text by counting the vowels present in each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o': 5, 'e': 3, 'i': 4, 'a': 3, 'u': 1}\n",
      "['o', 'e', 'i', 'a', 'o', 'e', 'o', 'o', 'o', 'i', 'e', 'a', 'i', 'i', 'a', 'u']\n",
      "[5, 3, 4, 3, 1]\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "def syllable_count(x):\n",
    "    v = []\n",
    "    d = {}\n",
    "    for i in x:\n",
    "        if i in \"aeiou\":\n",
    "            v.append(i)\n",
    "            d[i] = d.get(i,0)+1     # checking purpose\n",
    "            \n",
    "    k = []\n",
    "    for i in d:\n",
    "        k.append(d[i])\n",
    "    print(d)\n",
    "    print(v)  \n",
    "    print(k)\n",
    "    print(np.sum(k))\n",
    "        \n",
    "    \n",
    "g = 'bore i am gone to london in england britian uk'\n",
    "\n",
    "syllable_count(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def syllable_count(x):\n",
    "    v = []\n",
    "    d = {}\n",
    "    for i in x:\n",
    "        if i in \"aeiou\":\n",
    "            v.append(i)\n",
    "            d[i] = d.get(i,0)+1\n",
    "            \n",
    "    k = []\n",
    "    for i in d:\n",
    "        k.append(d[i])\n",
    "\n",
    "    return np.sum(k)\n",
    "\n",
    "g = h['Transform_Text'][1]\n",
    "\n",
    "syllable_count(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['syllable count'] = df['Transform_Text'].apply(lambda x: syllable_count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>chara_count</th>\n",
       "      <th>average word length</th>\n",
       "      <th>syllable count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When people hear AI they often think about sen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>people hear ai often think sentient robots mag...</td>\n",
       "      <td>434</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>2780</td>\n",
       "      <td>6.405530</td>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With increasing computing power and more data,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>increasing computing power data potential valu...</td>\n",
       "      <td>383</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>2618</td>\n",
       "      <td>6.835509</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you were a fan of the 90’s film Clueless ba...</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>fan 90 film clueless back day remember protago...</td>\n",
       "      <td>1103</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>7515</td>\n",
       "      <td>6.813237</td>\n",
       "      <td>2904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>understanding exactly data ingested analyzed r...</td>\n",
       "      <td>254</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>1778</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the stone age to the modern world, from h...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>stone age modern world hunting gathering culti...</td>\n",
       "      <td>711</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>4640</td>\n",
       "      <td>6.526020</td>\n",
       "      <td>1840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  When people hear AI they often think about sen...   \n",
       "1  With increasing computing power and more data,...   \n",
       "2  If you were a fan of the 90’s film Clueless ba...   \n",
       "3  Understanding exactly how data is ingested, an...   \n",
       "4  From the stone age to the modern world, from h...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4  https://insights.blackcoffer.com/how-artificia...   \n",
       "\n",
       "                                      Transform_Text  word_counts  \\\n",
       "0  people hear ai often think sentient robots mag...          434   \n",
       "1  increasing computing power data potential valu...          383   \n",
       "2  fan 90 film clueless back day remember protago...         1103   \n",
       "3  understanding exactly data ingested analyzed r...          254   \n",
       "4  stone age modern world hunting gathering culti...          711   \n",
       "\n",
       "   average number of words per sentence  chara_count  average word length  \\\n",
       "0                             18.083333         2780             6.405530   \n",
       "1                             13.678571         2618             6.835509   \n",
       "2                             14.324675         7515             6.813237   \n",
       "3                             16.933333         1778             7.000000   \n",
       "4                             10.611940         4640             6.526020   \n",
       "\n",
       "   syllable count  \n",
       "0            1074  \n",
       "1             996  \n",
       "2            2904  \n",
       "3             694  \n",
       "4            1840  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPLEX Word Count\n",
    "\n",
    "Complex words are words in the text that contain more than two Syllables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import  Counter\n",
    "\n",
    "def complex_word_count(x):\n",
    "    \n",
    "    syllable = 'aeiou'\n",
    "    \n",
    "    t = x.split()\n",
    "    \n",
    "    v = []\n",
    "    \n",
    "    for i in t:\n",
    "        words = i.split()\n",
    "        c=Counter()\n",
    "        \n",
    "        for word in words:\n",
    "            c.update(set(word))\n",
    "\n",
    "        n = 0\n",
    "        for a in c.most_common():\n",
    "            if a[0] in syllable:\n",
    "                if a[1] >= 2:\n",
    "                    n += 1\n",
    "                \n",
    "        m = 0\n",
    "        p = []\n",
    "        for a in c.most_common():\n",
    "            if a[0] in syllable:\n",
    "                p.append(a[0])\n",
    "        if len(p) >= 2:\n",
    "            m += 1\n",
    "        \n",
    "        if n >= 1 or m >= 1:\n",
    "            v.append(i)\n",
    "            \n",
    "    return len(v) \n",
    "\n",
    "g = h['Transform_Text'][1]\n",
    "\n",
    "complex_word_count(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>chara_count</th>\n",
       "      <th>average word length</th>\n",
       "      <th>syllable count</th>\n",
       "      <th>complex_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When people hear AI they often think about sen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>people hear ai often think sentient robots mag...</td>\n",
       "      <td>434</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>2780</td>\n",
       "      <td>6.405530</td>\n",
       "      <td>1074</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With increasing computing power and more data,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>increasing computing power data potential valu...</td>\n",
       "      <td>383</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>2618</td>\n",
       "      <td>6.835509</td>\n",
       "      <td>996</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you were a fan of the 90’s film Clueless ba...</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>fan 90 film clueless back day remember protago...</td>\n",
       "      <td>1103</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>7515</td>\n",
       "      <td>6.813237</td>\n",
       "      <td>2904</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>understanding exactly data ingested analyzed r...</td>\n",
       "      <td>254</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>1778</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>694</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the stone age to the modern world, from h...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>stone age modern world hunting gathering culti...</td>\n",
       "      <td>711</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>4640</td>\n",
       "      <td>6.526020</td>\n",
       "      <td>1840</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  When people hear AI they often think about sen...   \n",
       "1  With increasing computing power and more data,...   \n",
       "2  If you were a fan of the 90’s film Clueless ba...   \n",
       "3  Understanding exactly how data is ingested, an...   \n",
       "4  From the stone age to the modern world, from h...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4  https://insights.blackcoffer.com/how-artificia...   \n",
       "\n",
       "                                      Transform_Text  word_counts  \\\n",
       "0  people hear ai often think sentient robots mag...          434   \n",
       "1  increasing computing power data potential valu...          383   \n",
       "2  fan 90 film clueless back day remember protago...         1103   \n",
       "3  understanding exactly data ingested analyzed r...          254   \n",
       "4  stone age modern world hunting gathering culti...          711   \n",
       "\n",
       "   average number of words per sentence  chara_count  average word length  \\\n",
       "0                             18.083333         2780             6.405530   \n",
       "1                             13.678571         2618             6.835509   \n",
       "2                             14.324675         7515             6.813237   \n",
       "3                             16.933333         1778             7.000000   \n",
       "4                             10.611940         4640             6.526020   \n",
       "\n",
       "   syllable count  complex_count  \n",
       "0            1074            321  \n",
       "1             996            293  \n",
       "2            2904            884  \n",
       "3             694            195  \n",
       "4            1840            553  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['complex_count'] = np.nan\n",
    "\n",
    "df['complex_count'] = df['Transform_Text'].apply(lambda x: complex_word_count(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Readability\n",
    "\n",
    "Analysis of Readability is calculated using the Gunning Fox index formula described below.\n",
    "\n",
    "Average Sentence Length      =  the number of words / the number of sentences\n",
    "\n",
    "Percentage of Complex words  =  the number of complex words / the number of words \n",
    "\n",
    "Fog Index                    =  0.4 * (Average Sentence Length + Percentage of Complex words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-b2c86d949a96>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentence length'][i]  =   len(nltk.sent_tokenize(df['Text'][i]))\n",
      "<ipython-input-32-b2c86d949a96>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Average Sentence Length'][i] = df['word_counts'][i]/df['sentence length'][i]\n",
      "<ipython-input-32-b2c86d949a96>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Percentage of Complex words'][i] = df['complex_count'][i]/df['word_counts'][i]\n",
      "<ipython-input-32-b2c86d949a96>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Fog Index'][i] = 0.4 * (df['Average Sentence Length'][i] + df['Percentage of Complex words'][i])\n"
     ]
    }
   ],
   "source": [
    "df['sentence length'] = np.nan\n",
    "df['Average Sentence Length'] = np.nan\n",
    "df['Percentage of Complex words'] = np.nan\n",
    "df['Fog Index'] = np.nan\n",
    "\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    \n",
    "    df['sentence length'][i]  =   len(nltk.sent_tokenize(df['Text'][i]))\n",
    "    df['Average Sentence Length'][i] = df['word_counts'][i]/df['sentence length'][i]\n",
    "    df['Percentage of Complex words'][i] = df['complex_count'][i]/df['word_counts'][i] \n",
    "    df['Fog Index'][i] = 0.4 * (df['Average Sentence Length'][i] + df['Percentage of Complex words'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>chara_count</th>\n",
       "      <th>average word length</th>\n",
       "      <th>syllable count</th>\n",
       "      <th>complex_count</th>\n",
       "      <th>sentence length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Percentage of Complex words</th>\n",
       "      <th>Fog Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When people hear AI they often think about sen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>people hear ai often think sentient robots mag...</td>\n",
       "      <td>434</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>2780</td>\n",
       "      <td>6.405530</td>\n",
       "      <td>1074</td>\n",
       "      <td>321</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>0.739631</td>\n",
       "      <td>7.529186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With increasing computing power and more data,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>increasing computing power data potential valu...</td>\n",
       "      <td>383</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>2618</td>\n",
       "      <td>6.835509</td>\n",
       "      <td>996</td>\n",
       "      <td>293</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>0.765013</td>\n",
       "      <td>5.777434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you were a fan of the 90’s film Clueless ba...</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>fan 90 film clueless back day remember protago...</td>\n",
       "      <td>1103</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>7515</td>\n",
       "      <td>6.813237</td>\n",
       "      <td>2904</td>\n",
       "      <td>884</td>\n",
       "      <td>77.0</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>0.801451</td>\n",
       "      <td>6.050450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>understanding exactly data ingested analyzed r...</td>\n",
       "      <td>254</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>1778</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>694</td>\n",
       "      <td>195</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>7.080420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the stone age to the modern world, from h...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>stone age modern world hunting gathering culti...</td>\n",
       "      <td>711</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>4640</td>\n",
       "      <td>6.526020</td>\n",
       "      <td>1840</td>\n",
       "      <td>553</td>\n",
       "      <td>67.0</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>4.555887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  When people hear AI they often think about sen...   \n",
       "1  With increasing computing power and more data,...   \n",
       "2  If you were a fan of the 90’s film Clueless ba...   \n",
       "3  Understanding exactly how data is ingested, an...   \n",
       "4  From the stone age to the modern world, from h...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4  https://insights.blackcoffer.com/how-artificia...   \n",
       "\n",
       "                                      Transform_Text  word_counts  \\\n",
       "0  people hear ai often think sentient robots mag...          434   \n",
       "1  increasing computing power data potential valu...          383   \n",
       "2  fan 90 film clueless back day remember protago...         1103   \n",
       "3  understanding exactly data ingested analyzed r...          254   \n",
       "4  stone age modern world hunting gathering culti...          711   \n",
       "\n",
       "   average number of words per sentence  chara_count  average word length  \\\n",
       "0                             18.083333         2780             6.405530   \n",
       "1                             13.678571         2618             6.835509   \n",
       "2                             14.324675         7515             6.813237   \n",
       "3                             16.933333         1778             7.000000   \n",
       "4                             10.611940         4640             6.526020   \n",
       "\n",
       "   syllable count  complex_count  sentence length  Average Sentence Length  \\\n",
       "0            1074            321             24.0                18.083333   \n",
       "1             996            293             28.0                13.678571   \n",
       "2            2904            884             77.0                14.324675   \n",
       "3             694            195             15.0                16.933333   \n",
       "4            1840            553             67.0                10.611940   \n",
       "\n",
       "   Percentage of Complex words  Fog Index  \n",
       "0                     0.739631   7.529186  \n",
       "1                     0.765013   5.777434  \n",
       "2                     0.801451   6.050450  \n",
       "3                     0.767717   7.080420  \n",
       "4                     0.777778   4.555887  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS\n",
    "\n",
    "Sentimental analysis is the process of determining whether a piece of writing is positive, negative or neutral.\n",
    "\n",
    "The Master Dictionary (found here) is used for creating a dictionary of Positive and Negative words. We add only those words in the dictionary if they are not found in the Stop Words Lists. Use this url if above does not work https://sraf.nd.edu/textual-analysis/resources/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pd.read_csv('sentiment dict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARDVARK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARDVARKS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACUS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86526</th>\n",
       "      <td>ZYGOTE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86527</th>\n",
       "      <td>ZYGOTES</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86528</th>\n",
       "      <td>ZYGOTIC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86529</th>\n",
       "      <td>ZYMURGIES</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86530</th>\n",
       "      <td>ZYMURGY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86531 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  Negative  Positive\n",
       "0       AARDVARK         0         0\n",
       "1      AARDVARKS         0         0\n",
       "2          ABACI         0         0\n",
       "3          ABACK         0         0\n",
       "4         ABACUS         0         0\n",
       "...          ...       ...       ...\n",
       "86526     ZYGOTE         0         0\n",
       "86527    ZYGOTES         0         0\n",
       "86528    ZYGOTIC         0         0\n",
       "86529  ZYMURGIES         0         0\n",
       "86530    ZYMURGY         0         0\n",
       "\n",
       "[86531 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = sentiment[['Word','Negative','Positive']]\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "f = ['ZYGOTIC','BAD','DONE','EXCELLENT','WORSE']\n",
    "\n",
    "negative = 0\n",
    "positive = 0\n",
    "\n",
    "for i in dfs['Word']:\n",
    "    if i in f:\n",
    "        if dfs[dfs['Word']==i].Negative.any() == True:\n",
    "            negative += 1\n",
    "        if dfs[dfs['Word']==i].Positive.any() == True:                # CHECKING\n",
    "            positive += 1\n",
    "            \n",
    "print(negative),\n",
    "print(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to lower the word column in dfs to be used for sentiment score for the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word        0\n",
       "Negative    0\n",
       "Positive    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = dfs.dropna()\n",
    "dfs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'good', 'man']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 'the good man'\n",
    "w.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['word_lower'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "50741",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 50741",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-5b2bd7f0983d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mdfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word_lower'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Word'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 50741"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "        dfs['word_lower'][i] = dfs['Word'][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50742,len(dfs)):\n",
    "        dfs['word_lower'][i] = dfs['Word'][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['word_lower'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>word_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARDVARK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aardvark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARDVARKS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aardvarks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abaci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACUS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abacus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Negative  Positive word_lower\n",
       "0   AARDVARK         0         0   aardvark\n",
       "1  AARDVARKS         0         0  aardvarks\n",
       "2      ABACI         0         0      abaci\n",
       "3      ABACK         0         0      aback\n",
       "4     ABACUS         0         0     abacus"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Score\n",
    "\n",
    "Positive Score: This score is calculated by assigning the value of +1 for each word if found in the Positive Dictionary and then adding up all the values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the positive score for text.\n",
    "\n",
    "def positive(x):\n",
    "    \n",
    "    s = x.split()\n",
    "    \n",
    "    positive = 0\n",
    "    \n",
    "    for i in dfs['word_lower']:\n",
    "        if i in s:\n",
    "            if dfs[dfs['word_lower']==i].Positive.any() == True:\n",
    "                positive += 1\n",
    "            \n",
    "    return positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['positive_score'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['positive_score'][i] = positive(df['Transform_Text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>chara_count</th>\n",
       "      <th>average word length</th>\n",
       "      <th>syllable count</th>\n",
       "      <th>complex_count</th>\n",
       "      <th>sentence length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Percentage of Complex words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>positive_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When people hear AI they often think about sen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>people hear ai often think sentient robots mag...</td>\n",
       "      <td>434</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>2780</td>\n",
       "      <td>6.405530</td>\n",
       "      <td>1074</td>\n",
       "      <td>321</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>0.739631</td>\n",
       "      <td>7.529186</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With increasing computing power and more data,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>increasing computing power data potential valu...</td>\n",
       "      <td>383</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>2618</td>\n",
       "      <td>6.835509</td>\n",
       "      <td>996</td>\n",
       "      <td>293</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>0.765013</td>\n",
       "      <td>5.777434</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you were a fan of the 90’s film Clueless ba...</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>fan 90 film clueless back day remember protago...</td>\n",
       "      <td>1103</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>7515</td>\n",
       "      <td>6.813237</td>\n",
       "      <td>2904</td>\n",
       "      <td>884</td>\n",
       "      <td>77.0</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>0.801451</td>\n",
       "      <td>6.050450</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>understanding exactly data ingested analyzed r...</td>\n",
       "      <td>254</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>1778</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>694</td>\n",
       "      <td>195</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>7.080420</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the stone age to the modern world, from h...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>stone age modern world hunting gathering culti...</td>\n",
       "      <td>711</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>4640</td>\n",
       "      <td>6.526020</td>\n",
       "      <td>1840</td>\n",
       "      <td>553</td>\n",
       "      <td>67.0</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>4.555887</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  When people hear AI they often think about sen...   \n",
       "1  With increasing computing power and more data,...   \n",
       "2  If you were a fan of the 90’s film Clueless ba...   \n",
       "3  Understanding exactly how data is ingested, an...   \n",
       "4  From the stone age to the modern world, from h...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4  https://insights.blackcoffer.com/how-artificia...   \n",
       "\n",
       "                                      Transform_Text  word_counts  \\\n",
       "0  people hear ai often think sentient robots mag...          434   \n",
       "1  increasing computing power data potential valu...          383   \n",
       "2  fan 90 film clueless back day remember protago...         1103   \n",
       "3  understanding exactly data ingested analyzed r...          254   \n",
       "4  stone age modern world hunting gathering culti...          711   \n",
       "\n",
       "   average number of words per sentence  chara_count  average word length  \\\n",
       "0                             18.083333         2780             6.405530   \n",
       "1                             13.678571         2618             6.835509   \n",
       "2                             14.324675         7515             6.813237   \n",
       "3                             16.933333         1778             7.000000   \n",
       "4                             10.611940         4640             6.526020   \n",
       "\n",
       "   syllable count  complex_count  sentence length  Average Sentence Length  \\\n",
       "0            1074            321             24.0                18.083333   \n",
       "1             996            293             28.0                13.678571   \n",
       "2            2904            884             77.0                14.324675   \n",
       "3             694            195             15.0                16.933333   \n",
       "4            1840            553             67.0                10.611940   \n",
       "\n",
       "   Percentage of Complex words  Fog Index  positive_score  \n",
       "0                     0.739631   7.529186             4.0  \n",
       "1                     0.765013   5.777434             9.0  \n",
       "2                     0.801451   6.050450            27.0  \n",
       "3                     0.767717   7.080420             5.0  \n",
       "4                     0.777778   4.555887            19.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_word(x):\n",
    "    \n",
    "    s = x.split()\n",
    "    \n",
    "    positive_word = []\n",
    "    \n",
    "    for i in dfs['word_lower']:\n",
    "        if i in s:\n",
    "            if dfs[dfs['word_lower']==i].Positive.any() == True:   # checking which words are positive\n",
    "                positive_word.append(i)\n",
    "            \n",
    "    print(positive_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'better', 'easy', 'success']\n"
     ]
    }
   ],
   "source": [
    "df['positive_word'] = np.nan\n",
    "\n",
    "for i in range(1):\n",
    "    df['positive_word'][i] = positive_word(df['Transform_Text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('positive_word',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEGATIVE Score\n",
    "\n",
    "Negative Score: This score is calculated by assigning the value of -1 for each word if found in the Negative Dictionary and then adding up all the values. We multiply the score with -1 so that the score is a positive number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_score(x):\n",
    "    \n",
    "    s = x.split()\n",
    "    \n",
    "    negative = 0\n",
    "    \n",
    "    for i in dfs['word_lower']:\n",
    "        if i in s:\n",
    "            if dfs[dfs['word_lower']==i].Negative.any() == True:\n",
    "                negative += 1\n",
    "            \n",
    "    return negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['negative_score'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['negative_score'][i] = negative_score(df['Transform_Text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>chara_count</th>\n",
       "      <th>average word length</th>\n",
       "      <th>syllable count</th>\n",
       "      <th>complex_count</th>\n",
       "      <th>sentence length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Percentage of Complex words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When people hear AI they often think about sen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>people hear ai often think sentient robots mag...</td>\n",
       "      <td>434</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>2780</td>\n",
       "      <td>6.405530</td>\n",
       "      <td>1074</td>\n",
       "      <td>321</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>0.739631</td>\n",
       "      <td>7.529186</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With increasing computing power and more data,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>increasing computing power data potential valu...</td>\n",
       "      <td>383</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>2618</td>\n",
       "      <td>6.835509</td>\n",
       "      <td>996</td>\n",
       "      <td>293</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>0.765013</td>\n",
       "      <td>5.777434</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you were a fan of the 90’s film Clueless ba...</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>fan 90 film clueless back day remember protago...</td>\n",
       "      <td>1103</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>7515</td>\n",
       "      <td>6.813237</td>\n",
       "      <td>2904</td>\n",
       "      <td>884</td>\n",
       "      <td>77.0</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>0.801451</td>\n",
       "      <td>6.050450</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>understanding exactly data ingested analyzed r...</td>\n",
       "      <td>254</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>1778</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>694</td>\n",
       "      <td>195</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>7.080420</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the stone age to the modern world, from h...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>stone age modern world hunting gathering culti...</td>\n",
       "      <td>711</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>4640</td>\n",
       "      <td>6.526020</td>\n",
       "      <td>1840</td>\n",
       "      <td>553</td>\n",
       "      <td>67.0</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>4.555887</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  When people hear AI they often think about sen...   \n",
       "1  With increasing computing power and more data,...   \n",
       "2  If you were a fan of the 90’s film Clueless ba...   \n",
       "3  Understanding exactly how data is ingested, an...   \n",
       "4  From the stone age to the modern world, from h...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4  https://insights.blackcoffer.com/how-artificia...   \n",
       "\n",
       "                                      Transform_Text  word_counts  \\\n",
       "0  people hear ai often think sentient robots mag...          434   \n",
       "1  increasing computing power data potential valu...          383   \n",
       "2  fan 90 film clueless back day remember protago...         1103   \n",
       "3  understanding exactly data ingested analyzed r...          254   \n",
       "4  stone age modern world hunting gathering culti...          711   \n",
       "\n",
       "   average number of words per sentence  chara_count  average word length  \\\n",
       "0                             18.083333         2780             6.405530   \n",
       "1                             13.678571         2618             6.835509   \n",
       "2                             14.324675         7515             6.813237   \n",
       "3                             16.933333         1778             7.000000   \n",
       "4                             10.611940         4640             6.526020   \n",
       "\n",
       "   syllable count  complex_count  sentence length  Average Sentence Length  \\\n",
       "0            1074            321             24.0                18.083333   \n",
       "1             996            293             28.0                13.678571   \n",
       "2            2904            884             77.0                14.324675   \n",
       "3             694            195             15.0                16.933333   \n",
       "4            1840            553             67.0                10.611940   \n",
       "\n",
       "   Percentage of Complex words  Fog Index  positive_score  negative_score  \n",
       "0                     0.739631   7.529186             4.0             5.0  \n",
       "1                     0.765013   5.777434             9.0             6.0  \n",
       "2                     0.801451   6.050450            27.0            21.0  \n",
       "3                     0.767717   7.080420             5.0             1.0  \n",
       "4                     0.777778   4.555887            19.0            17.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polarity Score\n",
    "\n",
    "\n",
    "Polarity Score: This is the score that determines if a given text is positive or negative in nature.\n",
    "\n",
    "It is calculated by using the formula: \n",
    "\n",
    "Polarity Score = (Positive Score – Negative Score)/ ((Positive Score + Negative Score) + 0.000001)\n",
    "\n",
    "Range is from -1 to +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Polarity Score'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['Polarity Score'][i] = (df['positive_score'][i]-df['negative_score'][i])/ ((df['positive_score'][i] + df['negative_score'][i]) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>chara_count</th>\n",
       "      <th>average word length</th>\n",
       "      <th>syllable count</th>\n",
       "      <th>complex_count</th>\n",
       "      <th>sentence length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Percentage of Complex words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>Polarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When people hear AI they often think about sen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>people hear ai often think sentient robots mag...</td>\n",
       "      <td>434</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>2780</td>\n",
       "      <td>6.405530</td>\n",
       "      <td>1074</td>\n",
       "      <td>321</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>0.739631</td>\n",
       "      <td>7.529186</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With increasing computing power and more data,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>increasing computing power data potential valu...</td>\n",
       "      <td>383</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>2618</td>\n",
       "      <td>6.835509</td>\n",
       "      <td>996</td>\n",
       "      <td>293</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>0.765013</td>\n",
       "      <td>5.777434</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you were a fan of the 90’s film Clueless ba...</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>fan 90 film clueless back day remember protago...</td>\n",
       "      <td>1103</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>7515</td>\n",
       "      <td>6.813237</td>\n",
       "      <td>2904</td>\n",
       "      <td>884</td>\n",
       "      <td>77.0</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>0.801451</td>\n",
       "      <td>6.050450</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>understanding exactly data ingested analyzed r...</td>\n",
       "      <td>254</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>1778</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>694</td>\n",
       "      <td>195</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>7.080420</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the stone age to the modern world, from h...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>stone age modern world hunting gathering culti...</td>\n",
       "      <td>711</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>4640</td>\n",
       "      <td>6.526020</td>\n",
       "      <td>1840</td>\n",
       "      <td>553</td>\n",
       "      <td>67.0</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>4.555887</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  When people hear AI they often think about sen...   \n",
       "1  With increasing computing power and more data,...   \n",
       "2  If you were a fan of the 90’s film Clueless ba...   \n",
       "3  Understanding exactly how data is ingested, an...   \n",
       "4  From the stone age to the modern world, from h...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4  https://insights.blackcoffer.com/how-artificia...   \n",
       "\n",
       "                                      Transform_Text  word_counts  \\\n",
       "0  people hear ai often think sentient robots mag...          434   \n",
       "1  increasing computing power data potential valu...          383   \n",
       "2  fan 90 film clueless back day remember protago...         1103   \n",
       "3  understanding exactly data ingested analyzed r...          254   \n",
       "4  stone age modern world hunting gathering culti...          711   \n",
       "\n",
       "   average number of words per sentence  chara_count  average word length  \\\n",
       "0                             18.083333         2780             6.405530   \n",
       "1                             13.678571         2618             6.835509   \n",
       "2                             14.324675         7515             6.813237   \n",
       "3                             16.933333         1778             7.000000   \n",
       "4                             10.611940         4640             6.526020   \n",
       "\n",
       "   syllable count  complex_count  sentence length  Average Sentence Length  \\\n",
       "0            1074            321             24.0                18.083333   \n",
       "1             996            293             28.0                13.678571   \n",
       "2            2904            884             77.0                14.324675   \n",
       "3             694            195             15.0                16.933333   \n",
       "4            1840            553             67.0                10.611940   \n",
       "\n",
       "   Percentage of Complex words  Fog Index  positive_score  negative_score  \\\n",
       "0                     0.739631   7.529186             4.0             5.0   \n",
       "1                     0.765013   5.777434             9.0             6.0   \n",
       "2                     0.801451   6.050450            27.0            21.0   \n",
       "3                     0.767717   7.080420             5.0             1.0   \n",
       "4                     0.777778   4.555887            19.0            17.0   \n",
       "\n",
       "   Polarity Score  \n",
       "0       -0.111111  \n",
       "1        0.200000  \n",
       "2        0.125000  \n",
       "3        0.666667  \n",
       "4        0.055556  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBJECTIVITY SCORE\n",
    "\n",
    "Subjectivity Score: This is the score that determines if a given text is objective or subjective. \n",
    "\n",
    "It is calculated by using the formula: \n",
    "\n",
    "Subjectivity Score = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)\n",
    "\n",
    "Range is from 0 to +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.13926077545642765, subjectivity=0.48480990024468285)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(df['Transform_Text'][1])\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48480990024468285"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(df['Transform_Text'][1]).sentiment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subjectivity'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['subjectivity'][i] = TextBlob(df['Transform_Text'][i]).sentiment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>chara_count</th>\n",
       "      <th>average word length</th>\n",
       "      <th>syllable count</th>\n",
       "      <th>complex_count</th>\n",
       "      <th>sentence length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Percentage of Complex words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>Polarity Score</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When people hear AI they often think about sen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>people hear ai often think sentient robots mag...</td>\n",
       "      <td>434</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>2780</td>\n",
       "      <td>6.405530</td>\n",
       "      <td>1074</td>\n",
       "      <td>321</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>0.739631</td>\n",
       "      <td>7.529186</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.459438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With increasing computing power and more data,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>increasing computing power data potential valu...</td>\n",
       "      <td>383</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>2618</td>\n",
       "      <td>6.835509</td>\n",
       "      <td>996</td>\n",
       "      <td>293</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>0.765013</td>\n",
       "      <td>5.777434</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.484810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you were a fan of the 90’s film Clueless ba...</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>fan 90 film clueless back day remember protago...</td>\n",
       "      <td>1103</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>7515</td>\n",
       "      <td>6.813237</td>\n",
       "      <td>2904</td>\n",
       "      <td>884</td>\n",
       "      <td>77.0</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>0.801451</td>\n",
       "      <td>6.050450</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.542281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>understanding exactly data ingested analyzed r...</td>\n",
       "      <td>254</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>1778</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>694</td>\n",
       "      <td>195</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>7.080420</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.451277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the stone age to the modern world, from h...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>stone age modern world hunting gathering culti...</td>\n",
       "      <td>711</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>4640</td>\n",
       "      <td>6.526020</td>\n",
       "      <td>1840</td>\n",
       "      <td>553</td>\n",
       "      <td>67.0</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>4.555887</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.483817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  When people hear AI they often think about sen...   \n",
       "1  With increasing computing power and more data,...   \n",
       "2  If you were a fan of the 90’s film Clueless ba...   \n",
       "3  Understanding exactly how data is ingested, an...   \n",
       "4  From the stone age to the modern world, from h...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4  https://insights.blackcoffer.com/how-artificia...   \n",
       "\n",
       "                                      Transform_Text  word_counts  \\\n",
       "0  people hear ai often think sentient robots mag...          434   \n",
       "1  increasing computing power data potential valu...          383   \n",
       "2  fan 90 film clueless back day remember protago...         1103   \n",
       "3  understanding exactly data ingested analyzed r...          254   \n",
       "4  stone age modern world hunting gathering culti...          711   \n",
       "\n",
       "   average number of words per sentence  chara_count  average word length  \\\n",
       "0                             18.083333         2780             6.405530   \n",
       "1                             13.678571         2618             6.835509   \n",
       "2                             14.324675         7515             6.813237   \n",
       "3                             16.933333         1778             7.000000   \n",
       "4                             10.611940         4640             6.526020   \n",
       "\n",
       "   syllable count  complex_count  sentence length  Average Sentence Length  \\\n",
       "0            1074            321             24.0                18.083333   \n",
       "1             996            293             28.0                13.678571   \n",
       "2            2904            884             77.0                14.324675   \n",
       "3             694            195             15.0                16.933333   \n",
       "4            1840            553             67.0                10.611940   \n",
       "\n",
       "   Percentage of Complex words  Fog Index  positive_score  negative_score  \\\n",
       "0                     0.739631   7.529186             4.0             5.0   \n",
       "1                     0.765013   5.777434             9.0             6.0   \n",
       "2                     0.801451   6.050450            27.0            21.0   \n",
       "3                     0.767717   7.080420             5.0             1.0   \n",
       "4                     0.777778   4.555887            19.0            17.0   \n",
       "\n",
       "   Polarity Score  subjectivity  \n",
       "0       -0.111111      0.459438  \n",
       "1        0.200000      0.484810  \n",
       "2        0.125000      0.542281  \n",
       "3        0.666667      0.451277  \n",
       "4        0.055556      0.483817  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERSONAL PRONOUNS \n",
    "\n",
    "To calculate Personal Pronouns mentioned in the text, we use regex to find the counts of the words - “I,” “we,” “my,” “ours,” and “us”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n",
      "the my father\n"
     ]
    }
   ],
   "source": [
    "x = 'he is the my father'\n",
    "y = nlp(x)\n",
    "\n",
    "for noun in y.noun_chunks:\n",
    "    print(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('he is the my father')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n",
      "my\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.pos_ == 'PRON':\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERSONAL PRONOUNS'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[their,\n",
       " them,\n",
       " their,\n",
       " it,\n",
       " them,\n",
       " its,\n",
       " it,\n",
       " Our,\n",
       " their,\n",
       " What,\n",
       " them,\n",
       " they,\n",
       " it,\n",
       " Our,\n",
       " your,\n",
       " It,\n",
       " Our,\n",
       " your,\n",
       " they,\n",
       " their,\n",
       " it,\n",
       " we,\n",
       " we,\n",
       " them,\n",
       " it,\n",
       " our,\n",
       " it,\n",
       " it,\n",
       " our]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(df['Text'][1])\n",
    "tok = []\n",
    "for token in doc:\n",
    "    if token.pos_ == 'PRON':\n",
    "        tok.append(token)\n",
    "        \n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERSONAL PRONOUNS'][1] = tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>chara_count</th>\n",
       "      <th>average word length</th>\n",
       "      <th>syllable count</th>\n",
       "      <th>complex_count</th>\n",
       "      <th>sentence length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Percentage of Complex words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>Polarity Score</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When people hear AI they often think about sen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>people hear ai often think sentient robots mag...</td>\n",
       "      <td>434</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>2780</td>\n",
       "      <td>6.405530</td>\n",
       "      <td>1074</td>\n",
       "      <td>321</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>0.739631</td>\n",
       "      <td>7.529186</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.459438</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With increasing computing power and more data,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>increasing computing power data potential valu...</td>\n",
       "      <td>383</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>2618</td>\n",
       "      <td>6.835509</td>\n",
       "      <td>996</td>\n",
       "      <td>293</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>0.765013</td>\n",
       "      <td>5.777434</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.484810</td>\n",
       "      <td>[their, them, their, it, them, its, it, Our, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you were a fan of the 90’s film Clueless ba...</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>fan 90 film clueless back day remember protago...</td>\n",
       "      <td>1103</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>7515</td>\n",
       "      <td>6.813237</td>\n",
       "      <td>2904</td>\n",
       "      <td>884</td>\n",
       "      <td>77.0</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>0.801451</td>\n",
       "      <td>6.050450</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.542281</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>understanding exactly data ingested analyzed r...</td>\n",
       "      <td>254</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>1778</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>694</td>\n",
       "      <td>195</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>7.080420</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.451277</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the stone age to the modern world, from h...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>stone age modern world hunting gathering culti...</td>\n",
       "      <td>711</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>4640</td>\n",
       "      <td>6.526020</td>\n",
       "      <td>1840</td>\n",
       "      <td>553</td>\n",
       "      <td>67.0</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>4.555887</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.483817</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  When people hear AI they often think about sen...   \n",
       "1  With increasing computing power and more data,...   \n",
       "2  If you were a fan of the 90’s film Clueless ba...   \n",
       "3  Understanding exactly how data is ingested, an...   \n",
       "4  From the stone age to the modern world, from h...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4  https://insights.blackcoffer.com/how-artificia...   \n",
       "\n",
       "                                      Transform_Text  word_counts  \\\n",
       "0  people hear ai often think sentient robots mag...          434   \n",
       "1  increasing computing power data potential valu...          383   \n",
       "2  fan 90 film clueless back day remember protago...         1103   \n",
       "3  understanding exactly data ingested analyzed r...          254   \n",
       "4  stone age modern world hunting gathering culti...          711   \n",
       "\n",
       "   average number of words per sentence  chara_count  average word length  \\\n",
       "0                             18.083333         2780             6.405530   \n",
       "1                             13.678571         2618             6.835509   \n",
       "2                             14.324675         7515             6.813237   \n",
       "3                             16.933333         1778             7.000000   \n",
       "4                             10.611940         4640             6.526020   \n",
       "\n",
       "   syllable count  complex_count  sentence length  Average Sentence Length  \\\n",
       "0            1074            321             24.0                18.083333   \n",
       "1             996            293             28.0                13.678571   \n",
       "2            2904            884             77.0                14.324675   \n",
       "3             694            195             15.0                16.933333   \n",
       "4            1840            553             67.0                10.611940   \n",
       "\n",
       "   Percentage of Complex words  Fog Index  positive_score  negative_score  \\\n",
       "0                     0.739631   7.529186             4.0             5.0   \n",
       "1                     0.765013   5.777434             9.0             6.0   \n",
       "2                     0.801451   6.050450            27.0            21.0   \n",
       "3                     0.767717   7.080420             5.0             1.0   \n",
       "4                     0.777778   4.555887            19.0            17.0   \n",
       "\n",
       "   Polarity Score  subjectivity  \\\n",
       "0       -0.111111      0.459438   \n",
       "1        0.200000      0.484810   \n",
       "2        0.125000      0.542281   \n",
       "3        0.666667      0.451277   \n",
       "4        0.055556      0.483817   \n",
       "\n",
       "                                   PERSONAL PRONOUNS  \n",
       "0                                                NaN  \n",
       "1  [their, them, their, it, them, its, it, Our, t...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERSONAL PRONOUNS'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    doc = nlp(df['Text'][i])\n",
    "    tok = []\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'PRON':\n",
    "            tok.append(token)\n",
    "        \n",
    "    df['PERSONAL PRONOUNS'][i] = tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "      <th>Transform_Text</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>chara_count</th>\n",
       "      <th>average word length</th>\n",
       "      <th>syllable count</th>\n",
       "      <th>complex_count</th>\n",
       "      <th>sentence length</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Percentage of Complex words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>Polarity Score</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When people hear AI they often think about sen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>people hear ai often think sentient robots mag...</td>\n",
       "      <td>434</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>2780</td>\n",
       "      <td>6.405530</td>\n",
       "      <td>1074</td>\n",
       "      <td>321</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>0.739631</td>\n",
       "      <td>7.529186</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.459438</td>\n",
       "      <td>[they, it, it, We, there, what, their, there, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With increasing computing power and more data,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>increasing computing power data potential valu...</td>\n",
       "      <td>383</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>2618</td>\n",
       "      <td>6.835509</td>\n",
       "      <td>996</td>\n",
       "      <td>293</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>0.765013</td>\n",
       "      <td>5.777434</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.484810</td>\n",
       "      <td>[their, them, their, it, them, its, it, Our, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you were a fan of the 90’s film Clueless ba...</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>fan 90 film clueless back day remember protago...</td>\n",
       "      <td>1103</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>7515</td>\n",
       "      <td>6.813237</td>\n",
       "      <td>2904</td>\n",
       "      <td>884</td>\n",
       "      <td>77.0</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>0.801451</td>\n",
       "      <td>6.050450</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.542281</td>\n",
       "      <td>[you, you, She, it, her, her, everything, We, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>understanding exactly data ingested analyzed r...</td>\n",
       "      <td>254</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>1778</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>694</td>\n",
       "      <td>195</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>7.080420</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.451277</td>\n",
       "      <td>[they, they, its, they, their, it, its, we, them]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the stone age to the modern world, from h...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>stone age modern world hunting gathering culti...</td>\n",
       "      <td>711</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>4640</td>\n",
       "      <td>6.526020</td>\n",
       "      <td>1840</td>\n",
       "      <td>553</td>\n",
       "      <td>67.0</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>4.555887</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.483817</td>\n",
       "      <td>[we, what, I, we, our, we, us, our, what, We, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  When people hear AI they often think about sen...   \n",
       "1  With increasing computing power and more data,...   \n",
       "2  If you were a fan of the 90’s film Clueless ba...   \n",
       "3  Understanding exactly how data is ingested, an...   \n",
       "4  From the stone age to the modern world, from h...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://insights.blackcoffer.com/how-is-login-...   \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...   \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...   \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...   \n",
       "4  https://insights.blackcoffer.com/how-artificia...   \n",
       "\n",
       "                                      Transform_Text  word_counts  \\\n",
       "0  people hear ai often think sentient robots mag...          434   \n",
       "1  increasing computing power data potential valu...          383   \n",
       "2  fan 90 film clueless back day remember protago...         1103   \n",
       "3  understanding exactly data ingested analyzed r...          254   \n",
       "4  stone age modern world hunting gathering culti...          711   \n",
       "\n",
       "   average number of words per sentence  chara_count  average word length  \\\n",
       "0                             18.083333         2780             6.405530   \n",
       "1                             13.678571         2618             6.835509   \n",
       "2                             14.324675         7515             6.813237   \n",
       "3                             16.933333         1778             7.000000   \n",
       "4                             10.611940         4640             6.526020   \n",
       "\n",
       "   syllable count  complex_count  sentence length  Average Sentence Length  \\\n",
       "0            1074            321             24.0                18.083333   \n",
       "1             996            293             28.0                13.678571   \n",
       "2            2904            884             77.0                14.324675   \n",
       "3             694            195             15.0                16.933333   \n",
       "4            1840            553             67.0                10.611940   \n",
       "\n",
       "   Percentage of Complex words  Fog Index  positive_score  negative_score  \\\n",
       "0                     0.739631   7.529186             4.0             5.0   \n",
       "1                     0.765013   5.777434             9.0             6.0   \n",
       "2                     0.801451   6.050450            27.0            21.0   \n",
       "3                     0.767717   7.080420             5.0             1.0   \n",
       "4                     0.777778   4.555887            19.0            17.0   \n",
       "\n",
       "   Polarity Score  subjectivity  \\\n",
       "0       -0.111111      0.459438   \n",
       "1        0.200000      0.484810   \n",
       "2        0.125000      0.542281   \n",
       "3        0.666667      0.451277   \n",
       "4        0.055556      0.483817   \n",
       "\n",
       "                                   PERSONAL PRONOUNS  \n",
       "0  [they, it, it, We, there, what, their, there, ...  \n",
       "1  [their, them, their, it, them, its, it, Our, t...  \n",
       "2  [you, you, She, it, her, her, everything, We, ...  \n",
       "3  [they, they, its, they, their, it, its, we, them]  \n",
       "4  [we, what, I, we, our, we, us, our, what, We, ...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[you,\n",
       " you,\n",
       " She,\n",
       " it,\n",
       " her,\n",
       " her,\n",
       " everything,\n",
       " We,\n",
       " our,\n",
       " What,\n",
       " we,\n",
       " everyone,\n",
       " its,\n",
       " their,\n",
       " their,\n",
       " itself,\n",
       " them,\n",
       " its,\n",
       " them,\n",
       " their,\n",
       " their,\n",
       " they,\n",
       " they,\n",
       " their,\n",
       " them,\n",
       " their,\n",
       " their,\n",
       " they,\n",
       " their,\n",
       " us,\n",
       " our,\n",
       " its,\n",
       " It,\n",
       " them,\n",
       " them,\n",
       " them,\n",
       " their,\n",
       " them,\n",
       " their,\n",
       " what,\n",
       " you,\n",
       " your,\n",
       " It,\n",
       " your,\n",
       " you,\n",
       " its,\n",
       " them,\n",
       " You,\n",
       " your,\n",
       " it,\n",
       " it,\n",
       " they,\n",
       " its,\n",
       " It,\n",
       " us,\n",
       " We,\n",
       " We,\n",
       " we,\n",
       " We,\n",
       " our,\n",
       " She,\n",
       " we,\n",
       " We,\n",
       " it,\n",
       " our,\n",
       " She,\n",
       " we,\n",
       " we,\n",
       " our,\n",
       " our,\n",
       " it,\n",
       " it,\n",
       " everything,\n",
       " there,\n",
       " We,\n",
       " their,\n",
       " It,\n",
       " there]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PERSONAL PRONOUNS'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = df[['URL','positive_score','negative_score','Polarity Score','subjectivity','Average Sentence Length','Percentage of Complex words',\n",
    "            'Fog Index','average number of words per sentence','complex_count','word_counts','syllable count','PERSONAL PRONOUNS','average word length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>Polarity Score</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Percentage of Complex words</th>\n",
       "      <th>Fog Index</th>\n",
       "      <th>average number of words per sentence</th>\n",
       "      <th>complex_count</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>syllable count</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>average word length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.459438</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>0.739631</td>\n",
       "      <td>7.529186</td>\n",
       "      <td>18.083333</td>\n",
       "      <td>321</td>\n",
       "      <td>434</td>\n",
       "      <td>1074</td>\n",
       "      <td>[they, it, it, We, there, what, their, there, ...</td>\n",
       "      <td>6.405530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.484810</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>0.765013</td>\n",
       "      <td>5.777434</td>\n",
       "      <td>13.678571</td>\n",
       "      <td>293</td>\n",
       "      <td>383</td>\n",
       "      <td>996</td>\n",
       "      <td>[their, them, their, it, them, its, it, Our, t...</td>\n",
       "      <td>6.835509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.542281</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>0.801451</td>\n",
       "      <td>6.050450</td>\n",
       "      <td>14.324675</td>\n",
       "      <td>884</td>\n",
       "      <td>1103</td>\n",
       "      <td>2904</td>\n",
       "      <td>[you, you, She, it, her, her, everything, We, ...</td>\n",
       "      <td>6.813237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.451277</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>7.080420</td>\n",
       "      <td>16.933333</td>\n",
       "      <td>195</td>\n",
       "      <td>254</td>\n",
       "      <td>694</td>\n",
       "      <td>[they, they, its, they, their, it, its, we, them]</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.483817</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>4.555887</td>\n",
       "      <td>10.611940</td>\n",
       "      <td>553</td>\n",
       "      <td>711</td>\n",
       "      <td>1840</td>\n",
       "      <td>[we, what, I, we, our, we, us, our, what, We, ...</td>\n",
       "      <td>6.526020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  positive_score  \\\n",
       "0  https://insights.blackcoffer.com/how-is-login-...             4.0   \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...             9.0   \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...            27.0   \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...             5.0   \n",
       "4  https://insights.blackcoffer.com/how-artificia...            19.0   \n",
       "\n",
       "   negative_score  Polarity Score  subjectivity  Average Sentence Length  \\\n",
       "0             5.0       -0.111111      0.459438                18.083333   \n",
       "1             6.0        0.200000      0.484810                13.678571   \n",
       "2            21.0        0.125000      0.542281                14.324675   \n",
       "3             1.0        0.666667      0.451277                16.933333   \n",
       "4            17.0        0.055556      0.483817                10.611940   \n",
       "\n",
       "   Percentage of Complex words  Fog Index  \\\n",
       "0                     0.739631   7.529186   \n",
       "1                     0.765013   5.777434   \n",
       "2                     0.801451   6.050450   \n",
       "3                     0.767717   7.080420   \n",
       "4                     0.777778   4.555887   \n",
       "\n",
       "   average number of words per sentence  complex_count  word_counts  \\\n",
       "0                             18.083333            321          434   \n",
       "1                             13.678571            293          383   \n",
       "2                             14.324675            884         1103   \n",
       "3                             16.933333            195          254   \n",
       "4                             10.611940            553          711   \n",
       "\n",
       "   syllable count                                  PERSONAL PRONOUNS  \\\n",
       "0            1074  [they, it, it, We, there, what, their, there, ...   \n",
       "1             996  [their, them, their, it, them, its, it, Our, t...   \n",
       "2            2904  [you, you, She, it, her, her, everything, We, ...   \n",
       "3             694  [they, they, its, they, their, it, its, we, them]   \n",
       "4            1840  [we, what, I, we, our, we, us, our, what, We, ...   \n",
       "\n",
       "   average word length  \n",
       "0             6.405530  \n",
       "1             6.835509  \n",
       "2             6.813237  \n",
       "3             7.000000  \n",
       "4             6.526020  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Output Data Structure.xlsx\"\n",
    "\n",
    "submit.to_excel(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
